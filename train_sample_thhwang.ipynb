{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/openmmlab/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1 True\n",
      "0.28.0\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import ade_custom\n",
    "import dataset_split as ds\n",
    "import matplotlib.patches as mpatches\n",
    "import random\n",
    "\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "import mmseg\n",
    "print(mmseg.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add a new dataset\n",
    "data_root, img_dir, ann_dir 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "import random\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "# data 경로 설정\n",
    "data_root = '/data/36-3/'\n",
    "img_path = data_root + 'img_dir/'\n",
    "ann_path = data_root + 'ann_dir/'\n",
    "img_paths = glob(img_path+'*')\n",
    "ann_paths = glob(ann_path+'*')\n",
    "img_move_path = data_root + 'img_val/'\n",
    "ann_move_path = data_root + 'ann_val/'\n",
    "img_move_path_t = data_root + 'img_test/'\n",
    "ann_move_path_t = data_root + 'ann_test/'\n",
    "label_path = '/data/36-3/label_data/'\n",
    "label_folder = glob(label_path+'*')\n",
    "ds.root = data_root\n",
    "ds.label_path = label_path\n",
    "# new dataset classes, class별 색상\n",
    "classes = ade_custom.COLOR_PARAM.CLASSES\n",
    "palette = ade_custom.COLOR_PARAM.COLORMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Check Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Let's take a look at the segmentation map we got\n",
    "# img = Image.open('/mmsegmentation/data/36-3/ann_dir/24_193937_220616_170.png')\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# im = plt.imshow(np.array(img.convert('RGB')))\n",
    "\n",
    "# # create a patch (proxy artist) for every color \n",
    "# patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "#                           label=classes[i]) for i in range(8)]\n",
    "# # put those patched as legend-handles into the legend\n",
    "# plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "#            fontsize='large')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split dataset randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restore Done!\n"
     ]
    }
   ],
   "source": [
    "# split 한 데이터 다시 원래 이미지경로로 복원\n",
    "ds.restore_split(img_path, ann_path,img_move_path, ann_move_path, img_move_path_t, ann_move_path_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, file_list = ds.make_label_list(label_folder)\n",
    "classes = ds.dict_key_lower(classes)\n",
    "file_list = ds.dict_key_lower(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_label_split finish!\n",
      "label_split finish!\n"
     ]
    }
   ],
   "source": [
    "ds.s_label_split(img_path, ann_path, img_move_path, ann_move_path, img_move_path_t, ann_move_path_t, classes, file_list)\n",
    "ds.label_split(img_path, ann_path, img_move_path, ann_move_path, img_move_path_t, ann_move_path_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Train Image Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "\n",
    "class LeafData(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data, \n",
    "                 transform = None):\n",
    "        self.data      = data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # import\n",
    "        path  = self.data[idx]\n",
    "        img_array = np.fromfile(path, np.uint8)\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        # augmentations\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)['image']\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = A.Compose([A.Resize(height = 288, \n",
    "                           width  = 512), \n",
    "                  A.Normalize(mean = (0, 0, 0),\n",
    "                              std  = (1, 1, 1)),\n",
    "                  ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "img_paths = glob(img_path+'*')\n",
    "image_dataset = LeafData(data      = img_paths, \n",
    "                         transform = augs)\n",
    "\n",
    "# data loader\n",
    "image_loader = DataLoader(image_dataset, \n",
    "                          batch_size  = 8, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 4,\n",
    "                          pin_memory  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 855/855 [01:07<00:00, 12.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# placeholders\n",
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through images\n",
    "for inputs in tqdm(image_loader):\n",
    "    psum    += inputs.sum(axis        = [0, 2, 3])\n",
    "    psum_sq += (inputs ** 2).sum(axis = [0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel count\n",
    "count = len(img_paths) * 288 * 512\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [108.09 109.48 113.55]\n",
      "std:  [46.29 47.66 54.99]\n"
     ]
    }
   ],
   "source": [
    "means = np.round(np.array(total_mean * 256),2)\n",
    "stds = np.round(np.array(total_std * 256),2)\n",
    "\n",
    "# output\n",
    "print('mean: '  + str(means))\n",
    "print('std:  '  + str(stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6835\n",
      "839\n",
      "846\n",
      "6715\n",
      "839\n",
      "846\n"
     ]
    }
   ],
   "source": [
    "print(len(glob(data_root + 'img_dir/*')))\n",
    "print(len(glob(data_root + 'img_val/*')))\n",
    "print(len(glob(data_root + 'img_test/*')))\n",
    "\n",
    "print(len(glob(data_root + 'ann_dir/*')))\n",
    "print(len(glob(data_root + 'ann_val/*')))\n",
    "print(len(glob(data_root + 'ann_test/*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train:valid:test / 8:1:1 비율로 split\n",
    "split_dir = 'splits'\n",
    "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
    "origin_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "    osp.join(data_root, ann_path), suffix='.png')]\n",
    "valid_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "    osp.join(data_root, ann_move_path), suffix='.png')]\n",
    "test_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "    osp.join(data_root, ann_move_path_t), suffix='.png')]\n",
    "\n",
    "random.shuffle(origin_list)\n",
    "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
    "  f.writelines(line + '\\n' for line in origin_list)\n",
    "\n",
    "random.shuffle(valid_list)\n",
    "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
    "  f.writelines(line + '\\n' for line in valid_list)\n",
    "\n",
    "random.shuffle(test_list)\n",
    "with open(osp.join(data_root, split_dir, 'test.txt'), 'w') as f:\n",
    "  f.writelines(line + '\\n' for line in test_list)\n",
    "\n",
    "# with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
    "#   val_length = int(len(filename_list)*9/10)\n",
    "#   f.writelines(line + '\\n' for line in filename_list[train_length:val_length])\n",
    "\n",
    "# with open(osp.join(data_root, split_dir, 'test.txt'), 'w') as f:\n",
    "#   f.writelines(line + '\\n' for line in filename_list[val_length:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "# cfg = Config.fromfile('/home/mmsegmentation/configs/swin/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_22K.py')\n",
    "\n",
    "# cfg = Config.fromfile('/home/mmsegmentation/custom_config_train.py')\n",
    "\n",
    "cfg = Config.fromfile('/home/mmsegmentation/custom_config_train_3.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "norm_cfg = dict(type='BN', requires_grad=True)\n",
      "backbone_norm_cfg = dict(type='LN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    pretrained=None,\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer',\n",
      "        pretrain_img_size=384,\n",
      "        embed_dims=128,\n",
      "        patch_size=4,\n",
      "        window_size=12,\n",
      "        mlp_ratio=4,\n",
      "        depths=[2, 2, 18, 2],\n",
      "        num_heads=[4, 8, 16, 32],\n",
      "        strides=(4, 2, 2, 2),\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        patch_norm=True,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.3,\n",
      "        use_abs_pos_embed=False,\n",
      "        act_cfg=dict(type='GELU'),\n",
      "        norm_cfg=dict(type='LN', requires_grad=True),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            '/home/mmsegmentation/checkpoints/swin_base_patch4_window12_384_22k.pth'\n",
      "        )),\n",
      "    decode_head=dict(\n",
      "        type='UPerHead',\n",
      "        in_channels=[128, 256, 512, 1024],\n",
      "        in_index=[0, 1, 2, 3],\n",
      "        pool_scales=(1, 2, 3, 6),\n",
      "        channels=512,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=32,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=False,\n",
      "            loss_weight=1.0,\n",
      "            avg_non_ignore=True)),\n",
      "    auxiliary_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=512,\n",
      "        in_index=2,\n",
      "        channels=256,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=32,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=False,\n",
      "            loss_weight=0.4,\n",
      "            avg_non_ignore=True)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "dataset_type = 'CustomDataset'\n",
      "data_root = '/data/36-3/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[108.09, 109.48, 113.55], std=[46.29, 47.66, 54.99], to_rgb=True)\n",
      "crop_size = (512, 512)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "    dict(type='Resize', img_scale=(512, 512)),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[108.09, 109.48, 113.55],\n",
      "        std=[46.29, 47.66, 54.99],\n",
      "        to_rgb=True),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(512, 512),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[108.09, 109.48, 113.55],\n",
      "                std=[46.29, 47.66, 54.99],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='/data/36-3/',\n",
      "        img_dir='/data/36-3/img_dir/',\n",
      "        ann_dir='/data/36-3/ann_dir/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "            dict(type='Resize', img_scale=(512, 512)),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[108.09, 109.48, 113.55],\n",
      "                std=[46.29, 47.66, 54.99],\n",
      "                to_rgb=True),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "        ],\n",
      "        split='/data/36-3/splits/train.txt'),\n",
      "    val=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='/data/36-3/',\n",
      "        img_dir='/data/36-3/img_val/',\n",
      "        ann_dir='/data/36-3/ann_val/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(512, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[108.09, 109.48, 113.55],\n",
      "                        std=[46.29, 47.66, 54.99],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        split='/data/36-3/splits/val.txt'),\n",
      "    test=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='/data/36-3/',\n",
      "        img_dir='/data/36-3/img_test/',\n",
      "        ann_dir='/data/36-3/ann_test/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(512, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[108.09, 109.48, 113.55],\n",
      "                        std=[46.29, 47.66, 54.99],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        split='/data/36-3/splits/test.txt'))\n",
      "log_config = dict(\n",
      "    interval=1600, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = '/home/mmsegmentation/checkpoints/swin_base_patch4_window12_384_22k.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=6e-05,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.01,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0))))\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(\n",
      "    policy='poly',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1500,\n",
      "    warmup_ratio=1e-06,\n",
      "    power=1.0,\n",
      "    min_lr=0.0,\n",
      "    by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=160000)\n",
      "checkpoint_config = dict(by_epoch=False, interval=16000)\n",
      "evaluation = dict(interval=8000, metric='mIoU', pre_eval=True)\n",
      "checkpoint_file = '/home/mmsegmentation/checkpoints/swin_base_patch4_window12_384_22k.pth'\n",
      "work_dir = '/data/result/36-3/221011/'\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cuda'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "from mmseg.utils import get_device\n",
    "\n",
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = dict(type='LN', requires_grad=True)\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 32\n",
    "cfg.model.auxiliary_head.num_classes = 32\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'CustomDataset'\n",
    "cfg.data_root = '/data/36-3/'\n",
    "# batch_size\n",
    "cfg.data.samples_per_gpu = 8\n",
    "cfg.data.workers_per_gpu= 4\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    # 36-3 mean,std\n",
    "      mean=[means[0], means[1], means[2]],std=[stds[0], stds[1], stds[2]], to_rgb=True)\n",
    "#cfg.crop_size = (256, 256)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', reduce_zero_label = False),\n",
    "    dict(type='Resize', img_scale=(512, 512)),\n",
    "    #dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    #dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    " \n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(512, 512),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = img_path\n",
    "cfg.data.train.ann_dir = ann_path\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = data_root+'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = img_move_path\n",
    "cfg.data.val.ann_dir = ann_move_path\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = data_root+'splits/val.txt'\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = img_move_path_t\n",
    "cfg.data.test.ann_dir = ann_move_path_t\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = data_root+'splits/test.txt'\n",
    "\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch\n",
    "cfg.load_from = '/home/mmsegmentation/checkpoints/swin_base_patch4_window12_384_22k.pth'\n",
    "\n",
    "# cfg.load_from = 'data/result/36-3/test0913/iter_1600.pth'\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = '/data/result/36-3/221011/'\n",
    "\n",
    "cfg.runner.max_iters = 160000\n",
    "cfg.log_config.interval = 1600\n",
    "cfg.evaluation.interval = 8000\n",
    "cfg.checkpoint_config.interval = 16000\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device = get_device()\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mmseg.apis import set_random_seed\n",
    "# from mmseg.utils import get_device\n",
    "\n",
    "# # Modify dataset type and path\n",
    "# cfg.dataset_type = 'ADE20KDataset'\n",
    "# cfg.data_root = '/mmsegmentation/data/36-3/'\n",
    "\n",
    "# # We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# # use the mask branch\n",
    "# # cfg.load_from = '/mmsegmentation/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_22K_20210531_125459-429057bf.pth'\n",
    "\n",
    "# cfg.load_from = '/mmsegmentation/data/result/36-3/test0923/latest.pth'\n",
    "# # Set up working dir to save files and logs.\n",
    "# cfg.work_dir = '/mmsegmentation/data/result/36-3/test0927/'\n",
    "\n",
    "\n",
    "# # Set seed to facitate reproducing the result\n",
    "# cfg.seed = 42\n",
    "# set_random_seed(42, deterministic=False)\n",
    "# cfg.gpu_ids = range(1)\n",
    "# cfg.device = get_device()\n",
    "\n",
    "# # Let's have a look at the final config used for training\n",
    "# print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 11:41:22,083 - mmseg - INFO - Loaded 6715 images\n",
      "2022-10-12 11:41:23,111 - mmseg - INFO - Loaded 839 images\n",
      "2022-10-12 11:41:23,112 - mmseg - INFO - load checkpoint from local path: /home/mmsegmentation/checkpoints/swin_base_patch4_window12_384_22k.pth\n",
      "2022-10-12 11:41:23,195 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: model\n",
      "\n",
      "missing keys in source state_dict: backbone.patch_embed.projection.weight, backbone.patch_embed.projection.bias, backbone.patch_embed.norm.weight, backbone.patch_embed.norm.bias, backbone.stages.0.blocks.0.norm1.weight, backbone.stages.0.blocks.0.norm1.bias, backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.0.blocks.0.attn.w_msa.relative_position_index, backbone.stages.0.blocks.0.attn.w_msa.qkv.weight, backbone.stages.0.blocks.0.attn.w_msa.qkv.bias, backbone.stages.0.blocks.0.attn.w_msa.proj.weight, backbone.stages.0.blocks.0.attn.w_msa.proj.bias, backbone.stages.0.blocks.0.norm2.weight, backbone.stages.0.blocks.0.norm2.bias, backbone.stages.0.blocks.0.ffn.layers.0.0.weight, backbone.stages.0.blocks.0.ffn.layers.0.0.bias, backbone.stages.0.blocks.0.ffn.layers.1.weight, backbone.stages.0.blocks.0.ffn.layers.1.bias, backbone.stages.0.blocks.1.norm1.weight, backbone.stages.0.blocks.1.norm1.bias, backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.0.blocks.1.attn.w_msa.relative_position_index, backbone.stages.0.blocks.1.attn.w_msa.qkv.weight, backbone.stages.0.blocks.1.attn.w_msa.qkv.bias, backbone.stages.0.blocks.1.attn.w_msa.proj.weight, backbone.stages.0.blocks.1.attn.w_msa.proj.bias, backbone.stages.0.blocks.1.norm2.weight, backbone.stages.0.blocks.1.norm2.bias, backbone.stages.0.blocks.1.ffn.layers.0.0.weight, backbone.stages.0.blocks.1.ffn.layers.0.0.bias, backbone.stages.0.blocks.1.ffn.layers.1.weight, backbone.stages.0.blocks.1.ffn.layers.1.bias, backbone.stages.0.downsample.norm.weight, backbone.stages.0.downsample.norm.bias, backbone.stages.0.downsample.reduction.weight, backbone.stages.1.blocks.0.norm1.weight, backbone.stages.1.blocks.0.norm1.bias, backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.1.blocks.0.attn.w_msa.relative_position_index, backbone.stages.1.blocks.0.attn.w_msa.qkv.weight, backbone.stages.1.blocks.0.attn.w_msa.qkv.bias, backbone.stages.1.blocks.0.attn.w_msa.proj.weight, backbone.stages.1.blocks.0.attn.w_msa.proj.bias, backbone.stages.1.blocks.0.norm2.weight, backbone.stages.1.blocks.0.norm2.bias, backbone.stages.1.blocks.0.ffn.layers.0.0.weight, backbone.stages.1.blocks.0.ffn.layers.0.0.bias, backbone.stages.1.blocks.0.ffn.layers.1.weight, backbone.stages.1.blocks.0.ffn.layers.1.bias, backbone.stages.1.blocks.1.norm1.weight, backbone.stages.1.blocks.1.norm1.bias, backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.1.blocks.1.attn.w_msa.relative_position_index, backbone.stages.1.blocks.1.attn.w_msa.qkv.weight, backbone.stages.1.blocks.1.attn.w_msa.qkv.bias, backbone.stages.1.blocks.1.attn.w_msa.proj.weight, backbone.stages.1.blocks.1.attn.w_msa.proj.bias, backbone.stages.1.blocks.1.norm2.weight, backbone.stages.1.blocks.1.norm2.bias, backbone.stages.1.blocks.1.ffn.layers.0.0.weight, backbone.stages.1.blocks.1.ffn.layers.0.0.bias, backbone.stages.1.blocks.1.ffn.layers.1.weight, backbone.stages.1.blocks.1.ffn.layers.1.bias, backbone.stages.1.downsample.norm.weight, backbone.stages.1.downsample.norm.bias, backbone.stages.1.downsample.reduction.weight, backbone.stages.2.blocks.0.norm1.weight, backbone.stages.2.blocks.0.norm1.bias, backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.0.attn.w_msa.relative_position_index, backbone.stages.2.blocks.0.attn.w_msa.qkv.weight, backbone.stages.2.blocks.0.attn.w_msa.qkv.bias, backbone.stages.2.blocks.0.attn.w_msa.proj.weight, backbone.stages.2.blocks.0.attn.w_msa.proj.bias, backbone.stages.2.blocks.0.norm2.weight, backbone.stages.2.blocks.0.norm2.bias, backbone.stages.2.blocks.0.ffn.layers.0.0.weight, backbone.stages.2.blocks.0.ffn.layers.0.0.bias, backbone.stages.2.blocks.0.ffn.layers.1.weight, backbone.stages.2.blocks.0.ffn.layers.1.bias, backbone.stages.2.blocks.1.norm1.weight, backbone.stages.2.blocks.1.norm1.bias, backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.1.attn.w_msa.relative_position_index, backbone.stages.2.blocks.1.attn.w_msa.qkv.weight, backbone.stages.2.blocks.1.attn.w_msa.qkv.bias, backbone.stages.2.blocks.1.attn.w_msa.proj.weight, backbone.stages.2.blocks.1.attn.w_msa.proj.bias, backbone.stages.2.blocks.1.norm2.weight, backbone.stages.2.blocks.1.norm2.bias, backbone.stages.2.blocks.1.ffn.layers.0.0.weight, backbone.stages.2.blocks.1.ffn.layers.0.0.bias, backbone.stages.2.blocks.1.ffn.layers.1.weight, backbone.stages.2.blocks.1.ffn.layers.1.bias, backbone.stages.2.blocks.2.norm1.weight, backbone.stages.2.blocks.2.norm1.bias, backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.2.attn.w_msa.relative_position_index, backbone.stages.2.blocks.2.attn.w_msa.qkv.weight, backbone.stages.2.blocks.2.attn.w_msa.qkv.bias, backbone.stages.2.blocks.2.attn.w_msa.proj.weight, backbone.stages.2.blocks.2.attn.w_msa.proj.bias, backbone.stages.2.blocks.2.norm2.weight, backbone.stages.2.blocks.2.norm2.bias, backbone.stages.2.blocks.2.ffn.layers.0.0.weight, backbone.stages.2.blocks.2.ffn.layers.0.0.bias, backbone.stages.2.blocks.2.ffn.layers.1.weight, backbone.stages.2.blocks.2.ffn.layers.1.bias, backbone.stages.2.blocks.3.norm1.weight, backbone.stages.2.blocks.3.norm1.bias, backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.3.attn.w_msa.relative_position_index, backbone.stages.2.blocks.3.attn.w_msa.qkv.weight, backbone.stages.2.blocks.3.attn.w_msa.qkv.bias, backbone.stages.2.blocks.3.attn.w_msa.proj.weight, backbone.stages.2.blocks.3.attn.w_msa.proj.bias, backbone.stages.2.blocks.3.norm2.weight, backbone.stages.2.blocks.3.norm2.bias, backbone.stages.2.blocks.3.ffn.layers.0.0.weight, backbone.stages.2.blocks.3.ffn.layers.0.0.bias, backbone.stages.2.blocks.3.ffn.layers.1.weight, backbone.stages.2.blocks.3.ffn.layers.1.bias, backbone.stages.2.blocks.4.norm1.weight, backbone.stages.2.blocks.4.norm1.bias, backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.4.attn.w_msa.relative_position_index, backbone.stages.2.blocks.4.attn.w_msa.qkv.weight, backbone.stages.2.blocks.4.attn.w_msa.qkv.bias, backbone.stages.2.blocks.4.attn.w_msa.proj.weight, backbone.stages.2.blocks.4.attn.w_msa.proj.bias, backbone.stages.2.blocks.4.norm2.weight, backbone.stages.2.blocks.4.norm2.bias, backbone.stages.2.blocks.4.ffn.layers.0.0.weight, backbone.stages.2.blocks.4.ffn.layers.0.0.bias, backbone.stages.2.blocks.4.ffn.layers.1.weight, backbone.stages.2.blocks.4.ffn.layers.1.bias, backbone.stages.2.blocks.5.norm1.weight, backbone.stages.2.blocks.5.norm1.bias, backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.5.attn.w_msa.relative_position_index, backbone.stages.2.blocks.5.attn.w_msa.qkv.weight, backbone.stages.2.blocks.5.attn.w_msa.qkv.bias, backbone.stages.2.blocks.5.attn.w_msa.proj.weight, backbone.stages.2.blocks.5.attn.w_msa.proj.bias, backbone.stages.2.blocks.5.norm2.weight, backbone.stages.2.blocks.5.norm2.bias, backbone.stages.2.blocks.5.ffn.layers.0.0.weight, backbone.stages.2.blocks.5.ffn.layers.0.0.bias, backbone.stages.2.blocks.5.ffn.layers.1.weight, backbone.stages.2.blocks.5.ffn.layers.1.bias, backbone.stages.2.blocks.6.norm1.weight, backbone.stages.2.blocks.6.norm1.bias, backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.6.attn.w_msa.relative_position_index, backbone.stages.2.blocks.6.attn.w_msa.qkv.weight, backbone.stages.2.blocks.6.attn.w_msa.qkv.bias, backbone.stages.2.blocks.6.attn.w_msa.proj.weight, backbone.stages.2.blocks.6.attn.w_msa.proj.bias, backbone.stages.2.blocks.6.norm2.weight, backbone.stages.2.blocks.6.norm2.bias, backbone.stages.2.blocks.6.ffn.layers.0.0.weight, backbone.stages.2.blocks.6.ffn.layers.0.0.bias, backbone.stages.2.blocks.6.ffn.layers.1.weight, backbone.stages.2.blocks.6.ffn.layers.1.bias, backbone.stages.2.blocks.7.norm1.weight, backbone.stages.2.blocks.7.norm1.bias, backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.7.attn.w_msa.relative_position_index, backbone.stages.2.blocks.7.attn.w_msa.qkv.weight, backbone.stages.2.blocks.7.attn.w_msa.qkv.bias, backbone.stages.2.blocks.7.attn.w_msa.proj.weight, backbone.stages.2.blocks.7.attn.w_msa.proj.bias, backbone.stages.2.blocks.7.norm2.weight, backbone.stages.2.blocks.7.norm2.bias, backbone.stages.2.blocks.7.ffn.layers.0.0.weight, backbone.stages.2.blocks.7.ffn.layers.0.0.bias, backbone.stages.2.blocks.7.ffn.layers.1.weight, backbone.stages.2.blocks.7.ffn.layers.1.bias, backbone.stages.2.blocks.8.norm1.weight, backbone.stages.2.blocks.8.norm1.bias, backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.8.attn.w_msa.relative_position_index, backbone.stages.2.blocks.8.attn.w_msa.qkv.weight, backbone.stages.2.blocks.8.attn.w_msa.qkv.bias, backbone.stages.2.blocks.8.attn.w_msa.proj.weight, backbone.stages.2.blocks.8.attn.w_msa.proj.bias, backbone.stages.2.blocks.8.norm2.weight, backbone.stages.2.blocks.8.norm2.bias, backbone.stages.2.blocks.8.ffn.layers.0.0.weight, backbone.stages.2.blocks.8.ffn.layers.0.0.bias, backbone.stages.2.blocks.8.ffn.layers.1.weight, backbone.stages.2.blocks.8.ffn.layers.1.bias, backbone.stages.2.blocks.9.norm1.weight, backbone.stages.2.blocks.9.norm1.bias, backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.9.attn.w_msa.relative_position_index, backbone.stages.2.blocks.9.attn.w_msa.qkv.weight, backbone.stages.2.blocks.9.attn.w_msa.qkv.bias, backbone.stages.2.blocks.9.attn.w_msa.proj.weight, backbone.stages.2.blocks.9.attn.w_msa.proj.bias, backbone.stages.2.blocks.9.norm2.weight, backbone.stages.2.blocks.9.norm2.bias, backbone.stages.2.blocks.9.ffn.layers.0.0.weight, backbone.stages.2.blocks.9.ffn.layers.0.0.bias, backbone.stages.2.blocks.9.ffn.layers.1.weight, backbone.stages.2.blocks.9.ffn.layers.1.bias, backbone.stages.2.blocks.10.norm1.weight, backbone.stages.2.blocks.10.norm1.bias, backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.10.attn.w_msa.relative_position_index, backbone.stages.2.blocks.10.attn.w_msa.qkv.weight, backbone.stages.2.blocks.10.attn.w_msa.qkv.bias, backbone.stages.2.blocks.10.attn.w_msa.proj.weight, backbone.stages.2.blocks.10.attn.w_msa.proj.bias, backbone.stages.2.blocks.10.norm2.weight, backbone.stages.2.blocks.10.norm2.bias, backbone.stages.2.blocks.10.ffn.layers.0.0.weight, backbone.stages.2.blocks.10.ffn.layers.0.0.bias, backbone.stages.2.blocks.10.ffn.layers.1.weight, backbone.stages.2.blocks.10.ffn.layers.1.bias, backbone.stages.2.blocks.11.norm1.weight, backbone.stages.2.blocks.11.norm1.bias, backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.11.attn.w_msa.relative_position_index, backbone.stages.2.blocks.11.attn.w_msa.qkv.weight, backbone.stages.2.blocks.11.attn.w_msa.qkv.bias, backbone.stages.2.blocks.11.attn.w_msa.proj.weight, backbone.stages.2.blocks.11.attn.w_msa.proj.bias, backbone.stages.2.blocks.11.norm2.weight, backbone.stages.2.blocks.11.norm2.bias, backbone.stages.2.blocks.11.ffn.layers.0.0.weight, backbone.stages.2.blocks.11.ffn.layers.0.0.bias, backbone.stages.2.blocks.11.ffn.layers.1.weight, backbone.stages.2.blocks.11.ffn.layers.1.bias, backbone.stages.2.blocks.12.norm1.weight, backbone.stages.2.blocks.12.norm1.bias, backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.12.attn.w_msa.relative_position_index, backbone.stages.2.blocks.12.attn.w_msa.qkv.weight, backbone.stages.2.blocks.12.attn.w_msa.qkv.bias, backbone.stages.2.blocks.12.attn.w_msa.proj.weight, backbone.stages.2.blocks.12.attn.w_msa.proj.bias, backbone.stages.2.blocks.12.norm2.weight, backbone.stages.2.blocks.12.norm2.bias, backbone.stages.2.blocks.12.ffn.layers.0.0.weight, backbone.stages.2.blocks.12.ffn.layers.0.0.bias, backbone.stages.2.blocks.12.ffn.layers.1.weight, backbone.stages.2.blocks.12.ffn.layers.1.bias, backbone.stages.2.blocks.13.norm1.weight, backbone.stages.2.blocks.13.norm1.bias, backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.13.attn.w_msa.relative_position_index, backbone.stages.2.blocks.13.attn.w_msa.qkv.weight, backbone.stages.2.blocks.13.attn.w_msa.qkv.bias, backbone.stages.2.blocks.13.attn.w_msa.proj.weight, backbone.stages.2.blocks.13.attn.w_msa.proj.bias, backbone.stages.2.blocks.13.norm2.weight, backbone.stages.2.blocks.13.norm2.bias, backbone.stages.2.blocks.13.ffn.layers.0.0.weight, backbone.stages.2.blocks.13.ffn.layers.0.0.bias, backbone.stages.2.blocks.13.ffn.layers.1.weight, backbone.stages.2.blocks.13.ffn.layers.1.bias, backbone.stages.2.blocks.14.norm1.weight, backbone.stages.2.blocks.14.norm1.bias, backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.14.attn.w_msa.relative_position_index, backbone.stages.2.blocks.14.attn.w_msa.qkv.weight, backbone.stages.2.blocks.14.attn.w_msa.qkv.bias, backbone.stages.2.blocks.14.attn.w_msa.proj.weight, backbone.stages.2.blocks.14.attn.w_msa.proj.bias, backbone.stages.2.blocks.14.norm2.weight, backbone.stages.2.blocks.14.norm2.bias, backbone.stages.2.blocks.14.ffn.layers.0.0.weight, backbone.stages.2.blocks.14.ffn.layers.0.0.bias, backbone.stages.2.blocks.14.ffn.layers.1.weight, backbone.stages.2.blocks.14.ffn.layers.1.bias, backbone.stages.2.blocks.15.norm1.weight, backbone.stages.2.blocks.15.norm1.bias, backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.15.attn.w_msa.relative_position_index, backbone.stages.2.blocks.15.attn.w_msa.qkv.weight, backbone.stages.2.blocks.15.attn.w_msa.qkv.bias, backbone.stages.2.blocks.15.attn.w_msa.proj.weight, backbone.stages.2.blocks.15.attn.w_msa.proj.bias, backbone.stages.2.blocks.15.norm2.weight, backbone.stages.2.blocks.15.norm2.bias, backbone.stages.2.blocks.15.ffn.layers.0.0.weight, backbone.stages.2.blocks.15.ffn.layers.0.0.bias, backbone.stages.2.blocks.15.ffn.layers.1.weight, backbone.stages.2.blocks.15.ffn.layers.1.bias, backbone.stages.2.blocks.16.norm1.weight, backbone.stages.2.blocks.16.norm1.bias, backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.16.attn.w_msa.relative_position_index, backbone.stages.2.blocks.16.attn.w_msa.qkv.weight, backbone.stages.2.blocks.16.attn.w_msa.qkv.bias, backbone.stages.2.blocks.16.attn.w_msa.proj.weight, backbone.stages.2.blocks.16.attn.w_msa.proj.bias, backbone.stages.2.blocks.16.norm2.weight, backbone.stages.2.blocks.16.norm2.bias, backbone.stages.2.blocks.16.ffn.layers.0.0.weight, backbone.stages.2.blocks.16.ffn.layers.0.0.bias, backbone.stages.2.blocks.16.ffn.layers.1.weight, backbone.stages.2.blocks.16.ffn.layers.1.bias, backbone.stages.2.blocks.17.norm1.weight, backbone.stages.2.blocks.17.norm1.bias, backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.17.attn.w_msa.relative_position_index, backbone.stages.2.blocks.17.attn.w_msa.qkv.weight, backbone.stages.2.blocks.17.attn.w_msa.qkv.bias, backbone.stages.2.blocks.17.attn.w_msa.proj.weight, backbone.stages.2.blocks.17.attn.w_msa.proj.bias, backbone.stages.2.blocks.17.norm2.weight, backbone.stages.2.blocks.17.norm2.bias, backbone.stages.2.blocks.17.ffn.layers.0.0.weight, backbone.stages.2.blocks.17.ffn.layers.0.0.bias, backbone.stages.2.blocks.17.ffn.layers.1.weight, backbone.stages.2.blocks.17.ffn.layers.1.bias, backbone.stages.2.downsample.norm.weight, backbone.stages.2.downsample.norm.bias, backbone.stages.2.downsample.reduction.weight, backbone.stages.3.blocks.0.norm1.weight, backbone.stages.3.blocks.0.norm1.bias, backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.3.blocks.0.attn.w_msa.relative_position_index, backbone.stages.3.blocks.0.attn.w_msa.qkv.weight, backbone.stages.3.blocks.0.attn.w_msa.qkv.bias, backbone.stages.3.blocks.0.attn.w_msa.proj.weight, backbone.stages.3.blocks.0.attn.w_msa.proj.bias, backbone.stages.3.blocks.0.norm2.weight, backbone.stages.3.blocks.0.norm2.bias, backbone.stages.3.blocks.0.ffn.layers.0.0.weight, backbone.stages.3.blocks.0.ffn.layers.0.0.bias, backbone.stages.3.blocks.0.ffn.layers.1.weight, backbone.stages.3.blocks.0.ffn.layers.1.bias, backbone.stages.3.blocks.1.norm1.weight, backbone.stages.3.blocks.1.norm1.bias, backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.3.blocks.1.attn.w_msa.relative_position_index, backbone.stages.3.blocks.1.attn.w_msa.qkv.weight, backbone.stages.3.blocks.1.attn.w_msa.qkv.bias, backbone.stages.3.blocks.1.attn.w_msa.proj.weight, backbone.stages.3.blocks.1.attn.w_msa.proj.bias, backbone.stages.3.blocks.1.norm2.weight, backbone.stages.3.blocks.1.norm2.bias, backbone.stages.3.blocks.1.ffn.layers.0.0.weight, backbone.stages.3.blocks.1.ffn.layers.0.0.bias, backbone.stages.3.blocks.1.ffn.layers.1.weight, backbone.stages.3.blocks.1.ffn.layers.1.bias, backbone.norm0.weight, backbone.norm0.bias, backbone.norm1.weight, backbone.norm1.bias, backbone.norm2.weight, backbone.norm2.bias, backbone.norm3.weight, backbone.norm3.bias, decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.psp_modules.0.1.conv.weight, decode_head.psp_modules.0.1.bn.weight, decode_head.psp_modules.0.1.bn.bias, decode_head.psp_modules.0.1.bn.running_mean, decode_head.psp_modules.0.1.bn.running_var, decode_head.psp_modules.1.1.conv.weight, decode_head.psp_modules.1.1.bn.weight, decode_head.psp_modules.1.1.bn.bias, decode_head.psp_modules.1.1.bn.running_mean, decode_head.psp_modules.1.1.bn.running_var, decode_head.psp_modules.2.1.conv.weight, decode_head.psp_modules.2.1.bn.weight, decode_head.psp_modules.2.1.bn.bias, decode_head.psp_modules.2.1.bn.running_mean, decode_head.psp_modules.2.1.bn.running_var, decode_head.psp_modules.3.1.conv.weight, decode_head.psp_modules.3.1.bn.weight, decode_head.psp_modules.3.1.bn.bias, decode_head.psp_modules.3.1.bn.running_mean, decode_head.psp_modules.3.1.bn.running_var, decode_head.bottleneck.conv.weight, decode_head.bottleneck.bn.weight, decode_head.bottleneck.bn.bias, decode_head.bottleneck.bn.running_mean, decode_head.bottleneck.bn.running_var, decode_head.lateral_convs.0.conv.weight, decode_head.lateral_convs.0.bn.weight, decode_head.lateral_convs.0.bn.bias, decode_head.lateral_convs.0.bn.running_mean, decode_head.lateral_convs.0.bn.running_var, decode_head.lateral_convs.1.conv.weight, decode_head.lateral_convs.1.bn.weight, decode_head.lateral_convs.1.bn.bias, decode_head.lateral_convs.1.bn.running_mean, decode_head.lateral_convs.1.bn.running_var, decode_head.lateral_convs.2.conv.weight, decode_head.lateral_convs.2.bn.weight, decode_head.lateral_convs.2.bn.bias, decode_head.lateral_convs.2.bn.running_mean, decode_head.lateral_convs.2.bn.running_var, decode_head.fpn_convs.0.conv.weight, decode_head.fpn_convs.0.bn.weight, decode_head.fpn_convs.0.bn.bias, decode_head.fpn_convs.0.bn.running_mean, decode_head.fpn_convs.0.bn.running_var, decode_head.fpn_convs.1.conv.weight, decode_head.fpn_convs.1.bn.weight, decode_head.fpn_convs.1.bn.bias, decode_head.fpn_convs.1.bn.running_mean, decode_head.fpn_convs.1.bn.running_var, decode_head.fpn_convs.2.conv.weight, decode_head.fpn_convs.2.bn.weight, decode_head.fpn_convs.2.bn.bias, decode_head.fpn_convs.2.bn.running_mean, decode_head.fpn_convs.2.bn.running_var, decode_head.fpn_bottleneck.conv.weight, decode_head.fpn_bottleneck.bn.weight, decode_head.fpn_bottleneck.bn.bias, decode_head.fpn_bottleneck.bn.running_mean, decode_head.fpn_bottleneck.bn.running_var, auxiliary_head.conv_seg.weight, auxiliary_head.conv_seg.bias, auxiliary_head.convs.0.conv.weight, auxiliary_head.convs.0.bn.weight, auxiliary_head.convs.0.bn.bias, auxiliary_head.convs.0.bn.running_mean, auxiliary_head.convs.0.bn.running_var\n",
      "\n",
      "2022-10-12 11:41:23,201 - mmseg - INFO - Start running, host: root@c582f55fa2bc, work_dir: /data/result/36-3/221011\n",
      "2022-10-12 11:41:23,202 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-10-12 11:41:23,202 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters\n",
      "2022-10-12 11:41:23,203 - mmseg - INFO - Checkpoints will be saved to /data/result/36-3/221011 by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 11:55:32,453 - mmseg - INFO - Iter [1600/160000]\tlr: 5.940e-05, eta: 23:20:57, time: 0.531, data_time: 0.007, memory: 12927, decode.loss_ce: 0.7384, decode.acc_seg: 87.4877, aux.loss_ce: 0.4698, aux.acc_seg: 82.1689, loss: 1.2082\n",
      "2022-10-12 12:09:42,175 - mmseg - INFO - Iter [3200/160000]\tlr: 5.880e-05, eta: 23:07:19, time: 0.531, data_time: 0.009, memory: 12927, decode.loss_ce: 0.1330, decode.acc_seg: 95.9688, aux.loss_ce: 0.0897, aux.acc_seg: 93.9635, loss: 0.2227\n",
      "2022-10-12 12:23:51,629 - mmseg - INFO - Iter [4800/160000]\tlr: 5.820e-05, eta: 22:53:12, time: 0.531, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0912, decode.acc_seg: 97.0083, aux.loss_ce: 0.0624, aux.acc_seg: 95.1590, loss: 0.1536\n",
      "2022-10-12 12:38:01,687 - mmseg - INFO - Iter [6400/160000]\tlr: 5.760e-05, eta: 22:39:18, time: 0.531, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0748, decode.acc_seg: 97.4542, aux.loss_ce: 0.0521, aux.acc_seg: 95.7677, loss: 0.1268\n",
      "2022-10-12 12:52:11,424 - mmseg - INFO - Iter [8000/160000]\tlr: 5.700e-05, eta: 22:25:11, time: 0.531, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0651, decode.acc_seg: 97.7358, aux.loss_ce: 0.0461, aux.acc_seg: 96.1410, loss: 0.1112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 839/839, 16.7 task/s, elapsed: 50s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 12:53:01,818 - mmseg - INFO - per class results:\n",
      "2022-10-12 12:53:01,821 - mmseg - INFO - \n",
      "+-------------------+-------+-------+\n",
      "|       Class       |  IoU  |  Acc  |\n",
      "+-------------------+-------+-------+\n",
      "|     background    | 98.45 | 99.46 |\n",
      "|      vehicle      | 78.45 | 93.33 |\n",
      "|        bus        |  78.3 | 85.54 |\n",
      "|       truck       | 68.31 | 74.36 |\n",
      "|     policeCar     |  nan  |  nan  |\n",
      "|     ambulance     |  nan  |  nan  |\n",
      "|     schoolBus     | 40.65 | 41.68 |\n",
      "|      otherCar     | 63.21 | 83.53 |\n",
      "|     motorcycle    |  0.0  |  0.0  |\n",
      "|      bicycle      |  0.0  |  0.0  |\n",
      "|     twoWheeler    |  nan  |  nan  |\n",
      "|     pedestrian    |  0.0  |  0.0  |\n",
      "|       rider       |  0.0  |  0.0  |\n",
      "|     freespace     | 91.97 | 95.84 |\n",
      "|        curb       | 71.13 | 81.99 |\n",
      "|      sidewalk     |  0.0  |  0.0  |\n",
      "|     crossWalk     |  0.0  |  0.0  |\n",
      "|     safetyZone    | 83.59 | 89.95 |\n",
      "|     speedBump     |  nan  |  nan  |\n",
      "|      roadMark     | 27.91 | 31.53 |\n",
      "|     whiteLane     | 45.81 | 52.39 |\n",
      "|     yellowLane    |  47.8 | 61.25 |\n",
      "|      blueLane     |  57.5 | 66.72 |\n",
      "|      redLane      |  nan  |  nan  |\n",
      "|      stopLane     |  nan  |  nan  |\n",
      "| constructionGuide |  0.0  |  0.0  |\n",
      "|    trafficDrum    |  nan  |  nan  |\n",
      "|     rubberCone    | 21.92 | 22.75 |\n",
      "|    trafficSign    | 60.56 |  73.5 |\n",
      "|    trafficLight   |  0.0  |  0.0  |\n",
      "|  warningTriangle  |  nan  |  nan  |\n",
      "|       fence       | 79.45 | 87.06 |\n",
      "+-------------------+-------+-------+\n",
      "2022-10-12 12:53:01,821 - mmseg - INFO - Summary:\n",
      "2022-10-12 12:53:01,821 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 97.63 | 42.29 | 47.54 |\n",
      "+-------+-------+-------+\n",
      "2022-10-12 12:53:01,822 - mmseg - INFO - Iter(val) [839]\taAcc: 0.9763, mIoU: 0.4229, mAcc: 0.4754, IoU.background: 0.9845, IoU.vehicle: 0.7845, IoU.bus: 0.7830, IoU.truck: 0.6831, IoU.policeCar: nan, IoU.ambulance: nan, IoU.schoolBus: 0.4065, IoU.otherCar: 0.6321, IoU.motorcycle: 0.0000, IoU.bicycle: 0.0000, IoU.twoWheeler: nan, IoU.pedestrian: 0.0000, IoU.rider: 0.0000, IoU.freespace: 0.9197, IoU.curb: 0.7113, IoU.sidewalk: 0.0000, IoU.crossWalk: 0.0000, IoU.safetyZone: 0.8359, IoU.speedBump: nan, IoU.roadMark: 0.2791, IoU.whiteLane: 0.4581, IoU.yellowLane: 0.4780, IoU.blueLane: 0.5750, IoU.redLane: nan, IoU.stopLane: nan, IoU.constructionGuide: 0.0000, IoU.trafficDrum: nan, IoU.rubberCone: 0.2192, IoU.trafficSign: 0.6056, IoU.trafficLight: 0.0000, IoU.warningTriangle: nan, IoU.fence: 0.7945, Acc.background: 0.9946, Acc.vehicle: 0.9333, Acc.bus: 0.8554, Acc.truck: 0.7436, Acc.policeCar: nan, Acc.ambulance: nan, Acc.schoolBus: 0.4168, Acc.otherCar: 0.8353, Acc.motorcycle: 0.0000, Acc.bicycle: 0.0000, Acc.twoWheeler: nan, Acc.pedestrian: 0.0000, Acc.rider: 0.0000, Acc.freespace: 0.9584, Acc.curb: 0.8199, Acc.sidewalk: 0.0000, Acc.crossWalk: 0.0000, Acc.safetyZone: 0.8995, Acc.speedBump: nan, Acc.roadMark: 0.3153, Acc.whiteLane: 0.5239, Acc.yellowLane: 0.6125, Acc.blueLane: 0.6672, Acc.redLane: nan, Acc.stopLane: nan, Acc.constructionGuide: 0.0000, Acc.trafficDrum: nan, Acc.rubberCone: 0.2275, Acc.trafficSign: 0.7350, Acc.trafficLight: 0.0000, Acc.warningTriangle: nan, Acc.fence: 0.8706\n",
      "2022-10-12 13:07:11,751 - mmseg - INFO - Iter [9600/160000]\tlr: 5.640e-05, eta: 22:24:16, time: 0.563, data_time: 0.040, memory: 12927, decode.loss_ce: 0.0596, decode.acc_seg: 97.8991, aux.loss_ce: 0.0429, aux.acc_seg: 96.3387, loss: 0.1025\n",
      "2022-10-12 13:21:22,177 - mmseg - INFO - Iter [11200/160000]\tlr: 5.580e-05, eta: 22:08:17, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0544, decode.acc_seg: 98.0558, aux.loss_ce: 0.0398, aux.acc_seg: 96.5503, loss: 0.0942\n",
      "2022-10-12 13:35:32,382 - mmseg - INFO - Iter [12800/160000]\tlr: 5.520e-05, eta: 21:52:42, time: 0.531, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0504, decode.acc_seg: 98.1779, aux.loss_ce: 0.0374, aux.acc_seg: 96.7014, loss: 0.0879\n",
      "2022-10-12 13:49:42,456 - mmseg - INFO - Iter [14400/160000]\tlr: 5.460e-05, eta: 21:37:25, time: 0.531, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0478, decode.acc_seg: 98.2580, aux.loss_ce: 0.0359, aux.acc_seg: 96.8030, loss: 0.0837\n",
      "2022-10-12 14:03:52,291 - mmseg - INFO - Saving checkpoint at 16000 iterations\n",
      "2022-10-12 14:03:54,039 - mmseg - INFO - Iter [16000/160000]\tlr: 5.400e-05, eta: 21:22:35, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0447, decode.acc_seg: 98.3491, aux.loss_ce: 0.0343, aux.acc_seg: 96.9136, loss: 0.0790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 839/839, 16.6 task/s, elapsed: 50s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 14:04:44,510 - mmseg - INFO - per class results:\n",
      "2022-10-12 14:04:44,512 - mmseg - INFO - \n",
      "+-------------------+-------+-------+\n",
      "|       Class       |  IoU  |  Acc  |\n",
      "+-------------------+-------+-------+\n",
      "|     background    | 98.81 | 99.55 |\n",
      "|      vehicle      | 84.43 | 93.86 |\n",
      "|        bus        | 86.25 | 90.56 |\n",
      "|       truck       |  80.1 | 84.02 |\n",
      "|     policeCar     |  nan  |  nan  |\n",
      "|     ambulance     |  nan  |  nan  |\n",
      "|     schoolBus     | 41.67 | 41.94 |\n",
      "|      otherCar     | 73.44 | 88.68 |\n",
      "|     motorcycle    |  0.0  |  0.0  |\n",
      "|      bicycle      |  0.0  |  0.0  |\n",
      "|     twoWheeler    |  nan  |  nan  |\n",
      "|     pedestrian    | 33.11 | 35.68 |\n",
      "|       rider       |  0.0  |  0.0  |\n",
      "|     freespace     | 93.02 | 96.46 |\n",
      "|        curb       |  76.8 | 88.29 |\n",
      "|      sidewalk     |  0.0  |  0.0  |\n",
      "|     crossWalk     |  0.0  |  0.0  |\n",
      "|     safetyZone    | 87.54 |  92.6 |\n",
      "|     speedBump     |  nan  |  nan  |\n",
      "|      roadMark     | 41.62 | 50.44 |\n",
      "|     whiteLane     | 50.86 | 57.94 |\n",
      "|     yellowLane    | 48.36 |  60.2 |\n",
      "|      blueLane     | 62.58 | 73.31 |\n",
      "|      redLane      |  nan  |  nan  |\n",
      "|      stopLane     |  nan  |  nan  |\n",
      "| constructionGuide |  0.0  |  0.0  |\n",
      "|    trafficDrum    |  nan  |  nan  |\n",
      "|     rubberCone    | 53.04 | 70.24 |\n",
      "|    trafficSign    |  69.5 | 80.92 |\n",
      "|    trafficLight   |  0.0  |  0.0  |\n",
      "|  warningTriangle  |  nan  |  nan  |\n",
      "|       fence       | 84.15 | 91.01 |\n",
      "+-------------------+-------+-------+\n",
      "2022-10-12 14:04:44,512 - mmseg - INFO - Summary:\n",
      "2022-10-12 14:04:44,513 - mmseg - INFO - \n",
      "+------+-------+-------+\n",
      "| aAcc |  mIoU |  mAcc |\n",
      "+------+-------+-------+\n",
      "| 98.1 | 48.55 | 53.99 |\n",
      "+------+-------+-------+\n",
      "2022-10-12 14:04:44,513 - mmseg - INFO - Iter(val) [839]\taAcc: 0.9810, mIoU: 0.4855, mAcc: 0.5399, IoU.background: 0.9881, IoU.vehicle: 0.8443, IoU.bus: 0.8625, IoU.truck: 0.8010, IoU.policeCar: nan, IoU.ambulance: nan, IoU.schoolBus: 0.4167, IoU.otherCar: 0.7344, IoU.motorcycle: 0.0000, IoU.bicycle: 0.0000, IoU.twoWheeler: nan, IoU.pedestrian: 0.3311, IoU.rider: 0.0000, IoU.freespace: 0.9302, IoU.curb: 0.7680, IoU.sidewalk: 0.0000, IoU.crossWalk: 0.0000, IoU.safetyZone: 0.8754, IoU.speedBump: nan, IoU.roadMark: 0.4162, IoU.whiteLane: 0.5086, IoU.yellowLane: 0.4836, IoU.blueLane: 0.6258, IoU.redLane: nan, IoU.stopLane: nan, IoU.constructionGuide: 0.0000, IoU.trafficDrum: nan, IoU.rubberCone: 0.5304, IoU.trafficSign: 0.6950, IoU.trafficLight: 0.0000, IoU.warningTriangle: nan, IoU.fence: 0.8415, Acc.background: 0.9955, Acc.vehicle: 0.9386, Acc.bus: 0.9056, Acc.truck: 0.8402, Acc.policeCar: nan, Acc.ambulance: nan, Acc.schoolBus: 0.4194, Acc.otherCar: 0.8868, Acc.motorcycle: 0.0000, Acc.bicycle: 0.0000, Acc.twoWheeler: nan, Acc.pedestrian: 0.3568, Acc.rider: 0.0000, Acc.freespace: 0.9646, Acc.curb: 0.8829, Acc.sidewalk: 0.0000, Acc.crossWalk: 0.0000, Acc.safetyZone: 0.9260, Acc.speedBump: nan, Acc.roadMark: 0.5044, Acc.whiteLane: 0.5794, Acc.yellowLane: 0.6020, Acc.blueLane: 0.7331, Acc.redLane: nan, Acc.stopLane: nan, Acc.constructionGuide: 0.0000, Acc.trafficDrum: nan, Acc.rubberCone: 0.7024, Acc.trafficSign: 0.8092, Acc.trafficLight: 0.0000, Acc.warningTriangle: nan, Acc.fence: 0.9101\n",
      "2022-10-12 14:18:52,508 - mmseg - INFO - Iter [17600/160000]\tlr: 5.340e-05, eta: 21:14:11, time: 0.562, data_time: 0.039, memory: 12927, decode.loss_ce: 0.0421, decode.acc_seg: 98.4326, aux.loss_ce: 0.0327, aux.acc_seg: 97.0179, loss: 0.0748\n",
      "2022-10-12 14:33:03,586 - mmseg - INFO - Iter [19200/160000]\tlr: 5.280e-05, eta: 20:58:54, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0406, decode.acc_seg: 98.4797, aux.loss_ce: 0.0318, aux.acc_seg: 97.0754, loss: 0.0724\n",
      "2022-10-12 14:47:14,699 - mmseg - INFO - Iter [20800/160000]\tlr: 5.220e-05, eta: 20:43:47, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0398, decode.acc_seg: 98.5050, aux.loss_ce: 0.0315, aux.acc_seg: 97.0901, loss: 0.0713\n",
      "2022-10-12 15:01:25,206 - mmseg - INFO - Iter [22400/160000]\tlr: 5.160e-05, eta: 20:28:44, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0372, decode.acc_seg: 98.5842, aux.loss_ce: 0.0302, aux.acc_seg: 97.1879, loss: 0.0674\n",
      "2022-10-12 15:15:36,074 - mmseg - INFO - Iter [24000/160000]\tlr: 5.100e-05, eta: 20:13:51, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0363, decode.acc_seg: 98.6148, aux.loss_ce: 0.0297, aux.acc_seg: 97.2236, loss: 0.0660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 839/839, 16.8 task/s, elapsed: 50s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 15:16:25,957 - mmseg - INFO - per class results:\n",
      "2022-10-12 15:16:25,959 - mmseg - INFO - \n",
      "+-------------------+-------+-------+\n",
      "|       Class       |  IoU  |  Acc  |\n",
      "+-------------------+-------+-------+\n",
      "|     background    | 98.92 |  99.6 |\n",
      "|      vehicle      | 87.85 | 94.61 |\n",
      "|        bus        | 87.51 | 91.76 |\n",
      "|       truck       | 85.79 | 91.01 |\n",
      "|     policeCar     |  nan  |  nan  |\n",
      "|     ambulance     |  nan  |  nan  |\n",
      "|     schoolBus     | 45.05 | 46.26 |\n",
      "|      otherCar     | 75.65 |  89.9 |\n",
      "|     motorcycle    |  0.0  |  0.0  |\n",
      "|      bicycle      |  0.0  |  0.0  |\n",
      "|     twoWheeler    |  nan  |  nan  |\n",
      "|     pedestrian    | 51.31 | 66.75 |\n",
      "|       rider       |  0.0  |  0.0  |\n",
      "|     freespace     | 93.38 | 96.62 |\n",
      "|        curb       | 79.06 | 89.57 |\n",
      "|      sidewalk     | 33.65 |  50.0 |\n",
      "|     crossWalk     |  0.0  |  0.0  |\n",
      "|     safetyZone    | 87.88 | 92.98 |\n",
      "|     speedBump     |  nan  |  nan  |\n",
      "|      roadMark     |  44.1 | 55.45 |\n",
      "|     whiteLane     | 52.57 | 60.09 |\n",
      "|     yellowLane    | 49.18 | 59.23 |\n",
      "|      blueLane     | 64.01 | 74.45 |\n",
      "|      redLane      |  nan  |  nan  |\n",
      "|      stopLane     |  nan  |  nan  |\n",
      "| constructionGuide |  0.0  |  0.0  |\n",
      "|    trafficDrum    |  nan  |  nan  |\n",
      "|     rubberCone    | 56.62 | 78.93 |\n",
      "|    trafficSign    | 67.79 | 76.06 |\n",
      "|    trafficLight   | 22.57 | 22.63 |\n",
      "|  warningTriangle  |  nan  |  nan  |\n",
      "|       fence       | 85.82 | 91.91 |\n",
      "+-------------------+-------+-------+\n",
      "2022-10-12 15:16:25,959 - mmseg - INFO - Summary:\n",
      "2022-10-12 15:16:25,960 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 98.26 | 52.86 | 59.49 |\n",
      "+-------+-------+-------+\n",
      "2022-10-12 15:16:25,960 - mmseg - INFO - Iter(val) [839]\taAcc: 0.9826, mIoU: 0.5286, mAcc: 0.5949, IoU.background: 0.9892, IoU.vehicle: 0.8785, IoU.bus: 0.8751, IoU.truck: 0.8579, IoU.policeCar: nan, IoU.ambulance: nan, IoU.schoolBus: 0.4505, IoU.otherCar: 0.7565, IoU.motorcycle: 0.0000, IoU.bicycle: 0.0000, IoU.twoWheeler: nan, IoU.pedestrian: 0.5131, IoU.rider: 0.0000, IoU.freespace: 0.9338, IoU.curb: 0.7906, IoU.sidewalk: 0.3365, IoU.crossWalk: 0.0000, IoU.safetyZone: 0.8788, IoU.speedBump: nan, IoU.roadMark: 0.4410, IoU.whiteLane: 0.5257, IoU.yellowLane: 0.4918, IoU.blueLane: 0.6401, IoU.redLane: nan, IoU.stopLane: nan, IoU.constructionGuide: 0.0000, IoU.trafficDrum: nan, IoU.rubberCone: 0.5662, IoU.trafficSign: 0.6779, IoU.trafficLight: 0.2257, IoU.warningTriangle: nan, IoU.fence: 0.8582, Acc.background: 0.9960, Acc.vehicle: 0.9461, Acc.bus: 0.9176, Acc.truck: 0.9101, Acc.policeCar: nan, Acc.ambulance: nan, Acc.schoolBus: 0.4626, Acc.otherCar: 0.8990, Acc.motorcycle: 0.0000, Acc.bicycle: 0.0000, Acc.twoWheeler: nan, Acc.pedestrian: 0.6675, Acc.rider: 0.0000, Acc.freespace: 0.9662, Acc.curb: 0.8957, Acc.sidewalk: 0.5000, Acc.crossWalk: 0.0000, Acc.safetyZone: 0.9298, Acc.speedBump: nan, Acc.roadMark: 0.5545, Acc.whiteLane: 0.6009, Acc.yellowLane: 0.5923, Acc.blueLane: 0.7445, Acc.redLane: nan, Acc.stopLane: nan, Acc.constructionGuide: 0.0000, Acc.trafficDrum: nan, Acc.rubberCone: 0.7893, Acc.trafficSign: 0.7606, Acc.trafficLight: 0.2263, Acc.warningTriangle: nan, Acc.fence: 0.9191\n",
      "2022-10-12 15:30:35,913 - mmseg - INFO - Iter [25600/160000]\tlr: 5.040e-05, eta: 20:03:20, time: 0.562, data_time: 0.040, memory: 12927, decode.loss_ce: 0.0348, decode.acc_seg: 98.6638, aux.loss_ce: 0.0287, aux.acc_seg: 97.2914, loss: 0.0635\n",
      "2022-10-12 15:44:45,963 - mmseg - INFO - Iter [27200/160000]\tlr: 4.980e-05, eta: 19:48:14, time: 0.531, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0351, decode.acc_seg: 98.6525, aux.loss_ce: 0.0290, aux.acc_seg: 97.2633, loss: 0.0642\n",
      "2022-10-12 15:58:56,265 - mmseg - INFO - Iter [28800/160000]\tlr: 4.920e-05, eta: 19:33:15, time: 0.531, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0325, decode.acc_seg: 98.7328, aux.loss_ce: 0.0276, aux.acc_seg: 97.3668, loss: 0.0601\n",
      "2022-10-12 16:13:06,339 - mmseg - INFO - Iter [30400/160000]\tlr: 4.860e-05, eta: 19:18:21, time: 0.531, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0322, decode.acc_seg: 98.7449, aux.loss_ce: 0.0274, aux.acc_seg: 97.3801, loss: 0.0595\n",
      "2022-10-12 16:27:16,058 - mmseg - INFO - Saving checkpoint at 32000 iterations\n",
      "2022-10-12 16:27:17,779 - mmseg - INFO - Iter [32000/160000]\tlr: 4.800e-05, eta: 19:03:36, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0314, decode.acc_seg: 98.7679, aux.loss_ce: 0.0270, aux.acc_seg: 97.4002, loss: 0.0585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 839/839, 16.6 task/s, elapsed: 51s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 16:28:08,320 - mmseg - INFO - per class results:\n",
      "2022-10-12 16:28:08,321 - mmseg - INFO - \n",
      "+-------------------+-------+-------+\n",
      "|       Class       |  IoU  |  Acc  |\n",
      "+-------------------+-------+-------+\n",
      "|     background    | 98.99 | 99.63 |\n",
      "|      vehicle      |  89.2 | 94.59 |\n",
      "|        bus        | 89.58 |  93.3 |\n",
      "|       truck       | 86.05 | 91.36 |\n",
      "|     policeCar     |  nan  |  nan  |\n",
      "|     ambulance     |  nan  |  nan  |\n",
      "|     schoolBus     | 46.34 | 47.05 |\n",
      "|      otherCar     | 75.99 | 90.95 |\n",
      "|     motorcycle    |  0.0  |  0.0  |\n",
      "|      bicycle      |  0.0  |  0.0  |\n",
      "|     twoWheeler    |  nan  |  nan  |\n",
      "|     pedestrian    | 53.77 | 73.46 |\n",
      "|       rider       |  0.0  |  0.0  |\n",
      "|     freespace     |  93.6 | 96.97 |\n",
      "|        curb       | 79.26 | 88.75 |\n",
      "|      sidewalk     |  1.1  |  1.19 |\n",
      "|     crossWalk     |  0.0  |  0.0  |\n",
      "|     safetyZone    | 88.55 | 93.86 |\n",
      "|     speedBump     |  nan  |  nan  |\n",
      "|      roadMark     | 43.77 | 50.69 |\n",
      "|     whiteLane     | 50.46 | 55.67 |\n",
      "|     yellowLane    | 48.75 | 59.58 |\n",
      "|      blueLane     | 62.74 | 72.78 |\n",
      "|      redLane      |  nan  |  nan  |\n",
      "|      stopLane     |  nan  |  nan  |\n",
      "| constructionGuide |  0.0  |  0.0  |\n",
      "|    trafficDrum    |  nan  |  nan  |\n",
      "|     rubberCone    |  56.6 | 79.79 |\n",
      "|    trafficSign    | 74.03 | 82.13 |\n",
      "|    trafficLight   | 26.07 | 26.88 |\n",
      "|  warningTriangle  |  nan  |  nan  |\n",
      "|       fence       | 86.09 |  92.0 |\n",
      "+-------------------+-------+-------+\n",
      "2022-10-12 16:28:08,322 - mmseg - INFO - Summary:\n",
      "2022-10-12 16:28:08,322 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 98.32 | 52.12 | 57.94 |\n",
      "+-------+-------+-------+\n",
      "2022-10-12 16:28:08,323 - mmseg - INFO - Iter(val) [839]\taAcc: 0.9832, mIoU: 0.5212, mAcc: 0.5794, IoU.background: 0.9899, IoU.vehicle: 0.8920, IoU.bus: 0.8958, IoU.truck: 0.8605, IoU.policeCar: nan, IoU.ambulance: nan, IoU.schoolBus: 0.4634, IoU.otherCar: 0.7599, IoU.motorcycle: 0.0000, IoU.bicycle: 0.0000, IoU.twoWheeler: nan, IoU.pedestrian: 0.5377, IoU.rider: 0.0000, IoU.freespace: 0.9360, IoU.curb: 0.7926, IoU.sidewalk: 0.0110, IoU.crossWalk: 0.0000, IoU.safetyZone: 0.8855, IoU.speedBump: nan, IoU.roadMark: 0.4377, IoU.whiteLane: 0.5046, IoU.yellowLane: 0.4875, IoU.blueLane: 0.6274, IoU.redLane: nan, IoU.stopLane: nan, IoU.constructionGuide: 0.0000, IoU.trafficDrum: nan, IoU.rubberCone: 0.5660, IoU.trafficSign: 0.7403, IoU.trafficLight: 0.2607, IoU.warningTriangle: nan, IoU.fence: 0.8609, Acc.background: 0.9963, Acc.vehicle: 0.9459, Acc.bus: 0.9330, Acc.truck: 0.9136, Acc.policeCar: nan, Acc.ambulance: nan, Acc.schoolBus: 0.4705, Acc.otherCar: 0.9095, Acc.motorcycle: 0.0000, Acc.bicycle: 0.0000, Acc.twoWheeler: nan, Acc.pedestrian: 0.7346, Acc.rider: 0.0000, Acc.freespace: 0.9697, Acc.curb: 0.8875, Acc.sidewalk: 0.0119, Acc.crossWalk: 0.0000, Acc.safetyZone: 0.9386, Acc.speedBump: nan, Acc.roadMark: 0.5069, Acc.whiteLane: 0.5567, Acc.yellowLane: 0.5958, Acc.blueLane: 0.7278, Acc.redLane: nan, Acc.stopLane: nan, Acc.constructionGuide: 0.0000, Acc.trafficDrum: nan, Acc.rubberCone: 0.7979, Acc.trafficSign: 0.8213, Acc.trafficLight: 0.2688, Acc.warningTriangle: nan, Acc.fence: 0.9200\n",
      "2022-10-12 16:42:18,012 - mmseg - INFO - Iter [33600/160000]\tlr: 4.740e-05, eta: 18:51:59, time: 0.563, data_time: 0.040, memory: 12927, decode.loss_ce: 0.0308, decode.acc_seg: 98.7888, aux.loss_ce: 0.0267, aux.acc_seg: 97.4251, loss: 0.0575\n",
      "2022-10-12 16:56:25,927 - mmseg - INFO - Iter [35200/160000]\tlr: 4.680e-05, eta: 18:36:57, time: 0.530, data_time: 0.007, memory: 12927, decode.loss_ce: 0.0297, decode.acc_seg: 98.8234, aux.loss_ce: 0.0261, aux.acc_seg: 97.4638, loss: 0.0559\n",
      "2022-10-12 17:10:36,624 - mmseg - INFO - Iter [36800/160000]\tlr: 4.620e-05, eta: 18:22:09, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0290, decode.acc_seg: 98.8474, aux.loss_ce: 0.0258, aux.acc_seg: 97.4842, loss: 0.0548\n",
      "2022-10-12 17:24:47,742 - mmseg - INFO - Iter [38400/160000]\tlr: 4.560e-05, eta: 18:07:26, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0281, decode.acc_seg: 98.8747, aux.loss_ce: 0.0253, aux.acc_seg: 97.5190, loss: 0.0534\n",
      "2022-10-12 17:38:58,505 - mmseg - INFO - Iter [40000/160000]\tlr: 4.500e-05, eta: 17:52:44, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0277, decode.acc_seg: 98.8903, aux.loss_ce: 0.0251, aux.acc_seg: 97.5331, loss: 0.0527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 839/839, 16.5 task/s, elapsed: 51s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 17:39:49,398 - mmseg - INFO - per class results:\n",
      "2022-10-12 17:39:49,400 - mmseg - INFO - \n",
      "+-------------------+-------+-------+\n",
      "|       Class       |  IoU  |  Acc  |\n",
      "+-------------------+-------+-------+\n",
      "|     background    | 99.01 | 99.62 |\n",
      "|      vehicle      | 89.96 | 94.55 |\n",
      "|        bus        |  90.5 | 94.13 |\n",
      "|       truck       | 87.52 | 91.83 |\n",
      "|     policeCar     |  nan  |  nan  |\n",
      "|     ambulance     |  nan  |  nan  |\n",
      "|     schoolBus     | 47.61 |  48.4 |\n",
      "|      otherCar     | 77.95 | 91.93 |\n",
      "|     motorcycle    |  0.0  |  0.0  |\n",
      "|      bicycle      |  0.0  |  0.0  |\n",
      "|     twoWheeler    |  nan  |  nan  |\n",
      "|     pedestrian    | 52.53 | 71.13 |\n",
      "|       rider       |  0.0  |  0.0  |\n",
      "|     freespace     | 93.92 | 96.94 |\n",
      "|        curb       | 80.92 | 89.75 |\n",
      "|      sidewalk     | 65.68 | 74.09 |\n",
      "|     crossWalk     |  0.0  |  0.0  |\n",
      "|     safetyZone    | 89.71 | 95.23 |\n",
      "|     speedBump     |  nan  |  nan  |\n",
      "|      roadMark     |  46.4 | 55.25 |\n",
      "|     whiteLane     | 54.52 | 61.92 |\n",
      "|     yellowLane    | 51.27 | 63.33 |\n",
      "|      blueLane     | 65.11 | 73.65 |\n",
      "|      redLane      |  nan  |  nan  |\n",
      "|      stopLane     |  nan  |  nan  |\n",
      "| constructionGuide |  0.0  |  0.0  |\n",
      "|    trafficDrum    |  nan  |  nan  |\n",
      "|     rubberCone    | 59.39 | 80.68 |\n",
      "|    trafficSign    | 75.37 | 90.74 |\n",
      "|    trafficLight   |  29.8 | 30.89 |\n",
      "|  warningTriangle  |  nan  |  nan  |\n",
      "|       fence       | 86.41 | 92.14 |\n",
      "+-------------------+-------+-------+\n",
      "2022-10-12 17:39:49,401 - mmseg - INFO - Summary:\n",
      "2022-10-12 17:39:49,401 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 98.41 | 55.98 | 62.34 |\n",
      "+-------+-------+-------+\n",
      "2022-10-12 17:39:49,402 - mmseg - INFO - Iter(val) [839]\taAcc: 0.9841, mIoU: 0.5598, mAcc: 0.6234, IoU.background: 0.9901, IoU.vehicle: 0.8996, IoU.bus: 0.9050, IoU.truck: 0.8752, IoU.policeCar: nan, IoU.ambulance: nan, IoU.schoolBus: 0.4761, IoU.otherCar: 0.7795, IoU.motorcycle: 0.0000, IoU.bicycle: 0.0000, IoU.twoWheeler: nan, IoU.pedestrian: 0.5253, IoU.rider: 0.0000, IoU.freespace: 0.9392, IoU.curb: 0.8092, IoU.sidewalk: 0.6568, IoU.crossWalk: 0.0000, IoU.safetyZone: 0.8971, IoU.speedBump: nan, IoU.roadMark: 0.4640, IoU.whiteLane: 0.5452, IoU.yellowLane: 0.5127, IoU.blueLane: 0.6511, IoU.redLane: nan, IoU.stopLane: nan, IoU.constructionGuide: 0.0000, IoU.trafficDrum: nan, IoU.rubberCone: 0.5939, IoU.trafficSign: 0.7537, IoU.trafficLight: 0.2980, IoU.warningTriangle: nan, IoU.fence: 0.8641, Acc.background: 0.9962, Acc.vehicle: 0.9455, Acc.bus: 0.9413, Acc.truck: 0.9183, Acc.policeCar: nan, Acc.ambulance: nan, Acc.schoolBus: 0.4840, Acc.otherCar: 0.9193, Acc.motorcycle: 0.0000, Acc.bicycle: 0.0000, Acc.twoWheeler: nan, Acc.pedestrian: 0.7113, Acc.rider: 0.0000, Acc.freespace: 0.9694, Acc.curb: 0.8975, Acc.sidewalk: 0.7409, Acc.crossWalk: 0.0000, Acc.safetyZone: 0.9523, Acc.speedBump: nan, Acc.roadMark: 0.5525, Acc.whiteLane: 0.6192, Acc.yellowLane: 0.6333, Acc.blueLane: 0.7365, Acc.redLane: nan, Acc.stopLane: nan, Acc.constructionGuide: 0.0000, Acc.trafficDrum: nan, Acc.rubberCone: 0.8068, Acc.trafficSign: 0.9074, Acc.trafficLight: 0.3089, Acc.warningTriangle: nan, Acc.fence: 0.9214\n",
      "2022-10-12 17:53:59,422 - mmseg - INFO - Iter [41600/160000]\tlr: 4.440e-05, eta: 17:40:28, time: 0.563, data_time: 0.041, memory: 12927, decode.loss_ce: 0.0275, decode.acc_seg: 98.8978, aux.loss_ce: 0.0250, aux.acc_seg: 97.5423, loss: 0.0525\n",
      "2022-10-12 18:08:10,426 - mmseg - INFO - Iter [43200/160000]\tlr: 4.380e-05, eta: 17:25:44, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0270, decode.acc_seg: 98.9151, aux.loss_ce: 0.0248, aux.acc_seg: 97.5551, loss: 0.0517\n",
      "2022-10-12 18:22:21,283 - mmseg - INFO - Iter [44800/160000]\tlr: 4.320e-05, eta: 17:11:02, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0261, decode.acc_seg: 98.9420, aux.loss_ce: 0.0243, aux.acc_seg: 97.5889, loss: 0.0504\n",
      "2022-10-12 18:36:32,194 - mmseg - INFO - Iter [46400/160000]\tlr: 4.260e-05, eta: 16:56:22, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0257, decode.acc_seg: 98.9562, aux.loss_ce: 0.0241, aux.acc_seg: 97.6038, loss: 0.0498\n",
      "2022-10-12 18:50:42,751 - mmseg - INFO - Saving checkpoint at 48000 iterations\n",
      "2022-10-12 18:50:44,486 - mmseg - INFO - Iter [48000/160000]\tlr: 4.200e-05, eta: 16:41:48, time: 0.533, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0254, decode.acc_seg: 98.9679, aux.loss_ce: 0.0239, aux.acc_seg: 97.6130, loss: 0.0493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 839/839, 16.6 task/s, elapsed: 50s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 18:51:34,974 - mmseg - INFO - per class results:\n",
      "2022-10-12 18:51:34,976 - mmseg - INFO - \n",
      "+-------------------+-------+-------+\n",
      "|       Class       |  IoU  |  Acc  |\n",
      "+-------------------+-------+-------+\n",
      "|     background    | 99.01 | 99.63 |\n",
      "|      vehicle      | 89.81 | 94.81 |\n",
      "|        bus        | 89.98 | 93.32 |\n",
      "|       truck       | 84.43 | 89.13 |\n",
      "|     policeCar     |  nan  |  nan  |\n",
      "|     ambulance     |  nan  |  nan  |\n",
      "|     schoolBus     | 43.92 | 44.53 |\n",
      "|      otherCar     | 77.35 | 92.06 |\n",
      "|     motorcycle    |  0.0  |  0.0  |\n",
      "|      bicycle      |  0.0  |  0.0  |\n",
      "|     twoWheeler    |  nan  |  nan  |\n",
      "|     pedestrian    | 56.46 | 63.12 |\n",
      "|       rider       |  0.0  |  0.0  |\n",
      "|     freespace     | 93.83 | 97.08 |\n",
      "|        curb       | 79.54 | 89.48 |\n",
      "|      sidewalk     | 60.54 | 65.57 |\n",
      "|     crossWalk     |  0.0  |  0.0  |\n",
      "|     safetyZone    | 89.78 | 93.95 |\n",
      "|     speedBump     |  nan  |  nan  |\n",
      "|      roadMark     | 44.94 | 52.02 |\n",
      "|     whiteLane     | 53.21 | 59.19 |\n",
      "|     yellowLane    |  51.3 | 62.47 |\n",
      "|      blueLane     | 65.01 | 75.32 |\n",
      "|      redLane      |  nan  |  nan  |\n",
      "|      stopLane     |  nan  |  nan  |\n",
      "| constructionGuide |  0.0  |  0.0  |\n",
      "|    trafficDrum    |  nan  |  nan  |\n",
      "|     rubberCone    | 59.59 | 77.83 |\n",
      "|    trafficSign    | 74.75 | 81.36 |\n",
      "|    trafficLight   | 37.11 | 39.35 |\n",
      "|  warningTriangle  |  nan  |  nan  |\n",
      "|       fence       | 86.58 | 92.56 |\n",
      "+-------------------+-------+-------+\n",
      "2022-10-12 18:51:34,977 - mmseg - INFO - Summary:\n",
      "2022-10-12 18:51:34,977 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 98.38 | 55.71 | 60.95 |\n",
      "+-------+-------+-------+\n",
      "2022-10-12 18:51:34,977 - mmseg - INFO - Iter(val) [839]\taAcc: 0.9838, mIoU: 0.5571, mAcc: 0.6095, IoU.background: 0.9901, IoU.vehicle: 0.8981, IoU.bus: 0.8998, IoU.truck: 0.8443, IoU.policeCar: nan, IoU.ambulance: nan, IoU.schoolBus: 0.4392, IoU.otherCar: 0.7735, IoU.motorcycle: 0.0000, IoU.bicycle: 0.0000, IoU.twoWheeler: nan, IoU.pedestrian: 0.5646, IoU.rider: 0.0000, IoU.freespace: 0.9383, IoU.curb: 0.7954, IoU.sidewalk: 0.6054, IoU.crossWalk: 0.0000, IoU.safetyZone: 0.8978, IoU.speedBump: nan, IoU.roadMark: 0.4494, IoU.whiteLane: 0.5321, IoU.yellowLane: 0.5130, IoU.blueLane: 0.6501, IoU.redLane: nan, IoU.stopLane: nan, IoU.constructionGuide: 0.0000, IoU.trafficDrum: nan, IoU.rubberCone: 0.5959, IoU.trafficSign: 0.7475, IoU.trafficLight: 0.3711, IoU.warningTriangle: nan, IoU.fence: 0.8658, Acc.background: 0.9963, Acc.vehicle: 0.9481, Acc.bus: 0.9332, Acc.truck: 0.8913, Acc.policeCar: nan, Acc.ambulance: nan, Acc.schoolBus: 0.4453, Acc.otherCar: 0.9206, Acc.motorcycle: 0.0000, Acc.bicycle: 0.0000, Acc.twoWheeler: nan, Acc.pedestrian: 0.6312, Acc.rider: 0.0000, Acc.freespace: 0.9708, Acc.curb: 0.8948, Acc.sidewalk: 0.6557, Acc.crossWalk: 0.0000, Acc.safetyZone: 0.9395, Acc.speedBump: nan, Acc.roadMark: 0.5202, Acc.whiteLane: 0.5919, Acc.yellowLane: 0.6247, Acc.blueLane: 0.7532, Acc.redLane: nan, Acc.stopLane: nan, Acc.constructionGuide: 0.0000, Acc.trafficDrum: nan, Acc.rubberCone: 0.7783, Acc.trafficSign: 0.8136, Acc.trafficLight: 0.3935, Acc.warningTriangle: nan, Acc.fence: 0.9256\n",
      "2022-10-12 19:05:45,403 - mmseg - INFO - Iter [49600/160000]\tlr: 4.140e-05, eta: 16:29:03, time: 0.563, data_time: 0.040, memory: 12927, decode.loss_ce: 0.0248, decode.acc_seg: 98.9866, aux.loss_ce: 0.0236, aux.acc_seg: 97.6350, loss: 0.0484\n",
      "2022-10-12 19:19:55,859 - mmseg - INFO - Iter [51200/160000]\tlr: 4.080e-05, eta: 16:14:23, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0243, decode.acc_seg: 99.0033, aux.loss_ce: 0.0233, aux.acc_seg: 97.6551, loss: 0.0477\n",
      "2022-10-12 19:34:04,116 - mmseg - INFO - Iter [52800/160000]\tlr: 4.020e-05, eta: 15:59:40, time: 0.530, data_time: 0.008, memory: 12927, decode.loss_ce: 0.0244, decode.acc_seg: 99.0039, aux.loss_ce: 0.0234, aux.acc_seg: 97.6515, loss: 0.0477\n",
      "2022-10-12 19:48:14,566 - mmseg - INFO - Iter [54400/160000]\tlr: 3.960e-05, eta: 15:45:03, time: 0.532, data_time: 0.009, memory: 12927, decode.loss_ce: 0.0238, decode.acc_seg: 99.0231, aux.loss_ce: 0.0231, aux.acc_seg: 97.6723, loss: 0.0469\n"
     ]
    }
   ],
   "source": [
    "from mmseg.datasets import build_dataset, build_dataloader\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "# Clear Cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# print(datasets[0][0]['img'].__dict__)\n",
    "#print(datasets[0][0])\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(cfg.model)\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "print(len(model.CLASSES))\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [\n",
    "                [0,0,0],[128, 0, 0], [0, 128, 0], [0, 0, 128], [128, 128, 0],  [128, 0, 128], [0, 128, 128], [128, 128, 128], \n",
    "                [64, 0, 0], [0, 64, 0], [0, 0, 64], [64, 64, 0],  [64, 0, 64], [0, 64, 64], [64, 64, 64], \n",
    "                [192, 0, 0], [0, 192, 0], [0, 0, 192], [192, 192, 0],  [192, 0, 192], [0, 192, 192], [192, 192, 192], \n",
    "                [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128], \n",
    "                [192, 128, 128], [128, 64, 0], [0, 192, 128], [128, 192, 0], [0, 64, 128]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ade_custom\n",
    "model = torch.load(cfg.work_dir+'latest.pth')\n",
    "model['meta']['PALETTE'] = palette\n",
    "torch.save(model, cfg.work_dir+'latest_fix.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Inference with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/home/mmsegmentation/custom_config_test.py'\n",
    "checkpoint_file = '/data/result/36-3/test0928_2/latest_fix.pth'\n",
    "\n",
    "model = init_segmentor(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "\n",
    "img = '/data/36-3/img_test/16_142441_220613_150.jpg'\n",
    "\n",
    "result = inference_segmentor(model, img)\n",
    "\n",
    "show_result_pyplot(model, img, result, palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('openmmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c745df823b0b8fbc96bd327094d24a497ca88aeabc85de830d0531f0a8d26eb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
